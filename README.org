#+TITLE: Strong Normalization of the Simply-Typed Lambda Calculus in Lean by Decomposition Into the Call-By-Need SK Combinators
#+AUTHOR: Dowland Aiello
#+DATE: 5/26/25
#+BIBLIOGRAPHY: bibliography.bib
#+LATEX_HEADER: \usepackage{mathpartir}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \newtheorem{theorem}{Theorem}[section]
#+LATEX_HEADER: \newtheorem{lemma}[theorem]{Lemma}

* Abstract

Proofs of strong normalization of the simply-typed lambda calculus have been exhaustively enumerated in the literature. A common strategy invented by W. W. Tait known as "Tait's method," [cite:@harper2022] interprets types as sets of "well-behaving" terms which are known to be strongly normalizing and composed of expressions in some such set.
Strong normalization of the typed call-by-need SK combinator calculus has been comparatively under-studied. Herein, I demonstrate that the typical proof of strong normalization using Tait's method holds for the typed SK combinator calculus. I also show that decomposition of the STLC into SK combinator expressions simplifies the typical proof of strong normalization.

* A Type Discipline for the SK Combinators

I consider the usual SK combinator calculus defined as such:

#+BEGIN_EXPORT latex
\begin{align}
& K xy = x \\
& S xyz = xz (yz)
\end{align}
#+END_EXPORT

A natural interpretation of the combinators as typed functions results in the dependent typing:

#+NAME: inference:1
\label{inference:1}

#+BEGIN_EXPORT latex
\[
\inferrule
  { \Gamma \vdash A : K \ \Gamma,x : A \vdash B : L }
  { \Gamma \vdash (\forall x : A.B) : L}
\]
\[
\inferrule
  { }
  { \Gamma T_{n} : T_{n + 1} }
\]
\[
\inferrule
  { \Gamma \alpha : T_{n}, \beta : T_{m}, x : \alpha, y : \beta }
  { \Gamma \vdash K : (\forall x, y.\alpha) }
\]
\[
\inferrule
  { \Gamma \alpha : T_{n}, \beta : T_{m}, x : \alpha, y : \beta }
  { \Gamma \vdash K x y : \alpha }
\]
\[
\inferrule
  { \Gamma \alpha : T_{n}, \beta : T_{m}, \gamma : T_{o}, x : (\forall x : \alpha, y : \beta.\gamma), y : (\forall x : \alpha.\alpha), z : \alpha }
  { \Gamma \vdash S : (\forall x, y, z.\gamma) }
\]
\[
\inferrule
  { \Gamma \alpha : T_{n}, \beta : T_{m}, \gamma : T_{o}, x : (\forall x : \alpha, y : \beta.\gamma), y : (\forall x : \alpha.\alpha), z : \alpha }
  { \Gamma \vdash S x z (y z) : \gamma }
\]
#+END_EXPORT

#+NAME: decomplemma:1
\label{decomplemma:1}
* Decomposition of the Simply-Typed Lambda Calculus into Dependently Typed SK Combinators

I utilize an SK compilation scheme outlined in "The Implementation of Functional Programming Languages" [cite:@10.5555/1096899]:

#+BEGIN_EXPORT latex
\begin{align}
(\lambda x.e_{1}\ e_{2})\ arg &= S (\lambda x.e_{1}) (\lambda x.e_{2})\ arg \\
(\lambda x.x) &= SKK \\
(\lambda x.c) &= K c
\end{align}
#+END_EXPORT

I consider a generic simply-typed lambda calculus with base types $B$, a type constructor \rightarrow and the type universe:

#+BEGIN_EXPORT latex
\[
T = \{ t \mid t \in B\}\ \cup\ \{ t \mid \exists\  t_{1} \in T, t_{2} \in T, t = t_{1} \rightarrow t_{2} \}
\]
#+END_EXPORT

#+NAME: maplemma:1
\label{maplemma:1}
** Type Expressivity & Equivalence

I define a mapping (M_{t}) from the \rightarrow type constructor to \forall: $(\alpha \rightarrow \beta) \mapsto \forall x : \alpha.\beta$. I also assume the existence of a mapping (M_{c}) from the base types $B$ to arbitrary objects in my dependently-typed SK combinator calculus. Type inference is trivially derived from the above inference rules: $\forall c \in B, \exists\ t, t', c : t \implies t' = M_{t} t \implies M_{c} c : t$.

It follows that every well-typed expression in our simply-typed lambda calculus has an equivalent well-typed SK expression:

#+BEGIN_EXPORT latex
\begin{proof}
Assume (1) that for all $c \in B, \exists!\ c' \in M_{c}, c' = M_{c} c$.
Assume (2) that for all $\{t_{1}, t_{2}, t\} \subset T, t = (t_{1} \rightarrow t_{2}), \exists!\ t' \in M_{t}, t' = M_{t} t$.
Per \href{decomplemma:1}{above} and induction on (1) there exists a mapping from every lambda expression to an SK combinator expression.
It follows by induction on $e : t$, where $e$ is well-typed per the \href{decomplemma:1}{inference rules} that all $t \in$ the simply-typed $T$ are in $M_{t}$.
It suffices to conclude that all well-typed expressions have well-typed counterparts in the dependently-typed SK combinator calculus.
\end{proof}
#+END_EXPORT

* Proof

In order to prove strong normalization of the STLC, it suffices to demonstrate that a) no well-typed lambda calculus expression is inexpressible in the dependently-typed SK combinator calculus; and b) all well-typed SK combinator expressions are strongly normalizing.

** Comprehensiveness of the SK Mapping

#+BEGIN_EXPORT latex
\begin{proof}
Suppose (1) there exists some well-typed expression $e$ of type $t \in T$ in the STLC which is not representible in the dependently-typed SK combinator calculus. By induction: \\
\begin{itemize}
\item{If the expression is a constant, it must be contained in $M_{c}$, per the \href{maplemma:1}{above} lemma. \textbf{contradiction}} \\
\item{If the expression is a well-typed expression contained in $M_{c}$ which is a dependently-typed SK expression, its type is inferred per the \href{inference:1}{inference rules}. The expression is thus representible. \textbf{contradiction}} \\
\item If the expression is a well-typed lambda expression, its type is of the form: $\alpha \rightarrow \beta$, where $\{\alpha, \beta\} \subset T$. An image must exist in $M_{t}$ per \href{maplemma:1}{above} of the form $\forall x : \alpha.\beta$. \\
\begin{itemize}
  \item{Its body is also well-typed, and has a valid type. Its body is thus representible \textbf{by induction}.} \\
  \item{The expression is thus representible, per the \href{decomplemma:1}{decomposition rules}. \textbf{contradiction}} \\
\end{itemize}
\item{If the expression is a well-typed application $e_{1} e_{2}$, its left hand side is of type $\alpha \rightarrow \beta$, where $\{\alpha, \beta\} \subset T$. Its right hand side must be of type $beta$. The expression is thus of type $t$. By induction, the expression is representible. \textbf{contradiction}} \\
\end{itemize}

Conclusion: no expression exists which has no image in the set of well-typed dependently-typed SK combinator expressions.
\end{proof}
#+END_EXPORT

** Strong Normalization of the Typed SK Combinators

I assume the existence of a one-step reduction function: =eval_once=

I define strong-normalization inductively (where $e$ is an SK combinator expression) as:

#+BEGIN_SRC lean
inductive strongly_normalizing : Expr → Prop
  | trivial e : eval_once e = e → strongly_normalizing e
  | hard e : strongly_normalizing (eval_once e) →
             strongly_normalizing e
#+END_SRC

*** Reducibility Candidates

The $K$ combinator is trivially strongly normalizing. It invokes no function applications, although it may produce an expression which contains an application. For example:

#+BEGIN_EXPORT latex
\[
K (KK) y = KK
\]
#+END_EXPORT

Borrowing from Tait's method, I define a mapping $R(t)$ where $t$ is a type (expression) in our dependently-typed SK combinator calculus. The image of $t$ is a set containing every well-typed expression of type $t$ which is composed of expressions living in $R(t')$ for their respective types $t'$. I constrain the set such that all one-step reduxes of $K$ are in $R$.

#+BEGIN_EXPORT latex
\begin{gather*}
\forall \alpha : T_{n},\ \beta : T_{m},\ x : \alpha,\ y : \alpha,\ R(\forall x, y.\alpha) = \\
\{ K \mid  K : (\forall x, y.\alpha) \land \forall arg_{1} : \alpha,\ arg_{2} : \beta, \\
\text{\texttt{eval\_once}}\ K\  arg_{1}\  arg_{2} \in R(\alpha) \}
\end{gather*}
#+END_EXPORT

Or, more succinctly:

#+BEGIN_EXPORT latex
\[
\forall \alpha : T_{n},\ \beta : T_{m},\ x : \alpha,\ y : \alpha,\ R(\forall x, y.\alpha) =
\{ K \mid K : (\forall x,\ y.\alpha)\ \land\  arg_{1}\ \in R(\alpha) \}
\]
#+END_EXPORT

$R(t)$ can be similarly extended to include the S combinator.

#+BEGIN_EXPORT latex
\begin{gather*}
\forall \alpha : T_{n},\ \beta : T_{m},\ \gamma : T_{o},\ \\
T_{x} = (\forall x : \alpha, y : \beta.\gamma),\ T_{y} = (\forall x : \alpha.\alpha),\ T_{z} = \alpha,\ \\
x : T_{x},\ y : T_{y},\ z : T_{z}, \\
R(\forall x, y, z.\gamma) = \{ S \mid
  S : (\forall x, y, z.\gamma),\ \forall arg_{1} : T_{x},\ arg_{2} : T_{z},\ arg_{3} : T_{z}, \\
  arg_{1} \in R(T_{x}) \land arg_{2} \in R(T_{y}) \land arg_{3} \in R(T_{z}) \}
\end{gather*}
#+END_EXPORT

Expressions which are obviously reducible and inert are as follows:

#+BEGIN_EXPORT latex
\begin{gather*}
R(T_{n + 1}) = \{ T_{n} \}\ \\
\forall K : T_{n},\ L : T_{m},\ A : K,\ B : L,\ R(L) = \{ \text{fall} \mid ,\ \text{fall} = (\forall x : A.B) \land \text{fall} : L \}
\end{gather*}
#+END_EXPORT

*** Inductive Proof

It suffices in order to prove strong normalization of this sytem that a) all reducibility candidates in $R$ are strongly-normalizing; and c) all well-typed expression $(e : t)$ can be expressed using expressions in $R(t)$.

**** Preservation

In order to execute an inductive proof leveraging our definition of $R(t)$, it is useful to prove that evaluation maintains the typing of an expression.

#+BEGIN_EXPORT latex
\begin{lemma}
For all well-typed expressions, $e : t \implies (eval\_once\ e) : t$.
\begin{proof}
The proof is obvious for obviously reducible expressions of the form $T_{n}$ and $(\forall x:A.B)$. The $K : t$ combinator is inert ($\text{eval\_once}\ k = k \implies t = t'$) except when it is provided two well-typed arguments: $K (x : t_{1}) (y : t_{2})$. Per the \href{inference:1}{inference rules}, $(K x y) : t$ is of the type $t = t_{1}$. Evaluation of $K x y$ is defined to be equivalent to $x$. Thus, preservation is trivially achieved.
\end{proof}
\end{lemma}
#+END_EXPORT

**** Proof Execution

#+BEGIN_EXPORT latex
\begin{lemma}
All expressions $e$ which are well-typed with type $t$ and occupy the set $R(t)$ are strongly normalizing.
\begin{proof}
Inductively: \\
\begin{itemize}
\item All obviously reducing candidates are strongly normalizing:
\begin{itemize}
\item All expressions of the form $T_{n}$ are strongly normalizing, as they are inert.
\item All expressions of the form $(\forall x : A.B)$ are strongly normalizing, as they are inert.
\end{itemize}
\item All $K : t$ combinators in $R(t)$ are strongly normalizing. $K$ is insert, and invokes no function applications. By the definition of $R(t)$, $K \in R(t)$ will produce only one-step reduxes which are in $R$, and which are strongly normalizing \textbf{by induction}. Thus, the expression is \textbf{strongly normalizing}.
\item All $S : t$ combinators in $R(t)$ are strongly normalizing. $S$ is not inert, and invokes $xz (yz)$. However, $x$, $y$, and $z$ live in $R$, requiring that their one-step reduxes live in $R$ and are strongly-normalizing. The expression is strongly-normalizing \textbf{by induction}.
\end{itemize}
\end{proof}
\end{lemma}
\begin{lemma}
All well-typed expressions $(e : t)$ occupy the set $R(t)$.
\begin{proof}
The proof is trivially proven for objects of the form $T_{n}$ and $(\forall x:A.B)$, as above.
\begin{itemize}
\item All well-typed $K : t$ combinators are of the type $t = \forall x, y.\alpha$, where x is well-typed ($x : \alpha$) and y is well-typed ($y : \beta$). $x \in R(\alpha) \land y \in R(\beta)$ \textbf{by induction}.
\end{itemize}
\end{proof}
\end{lemma}
#+END_EXPORT

** Strong Normalization of the STLC
** Encoding in Lean

#+PRINT_BIBLIOGRAPHY:
